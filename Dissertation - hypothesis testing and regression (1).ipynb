{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Projects</th><th scope=col>Shannon diversity index</th><th scope=col>Normalized Shannon/NH</th><th scope=col>Simpson's index</th><th scope=col>Normalized Simpson/NGV</th><th scope=col>Distance to target Simpson</th><th scope=col>Distance to target Shannon</th><th scope=col>Success</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Bagel     </td><td>1.459482  </td><td>0.57      </td><td>0.7377778 </td><td>0.81      </td><td>-0.2107210</td><td>-0.5621189</td><td>0         </td></tr>\n",
       "\t<tr><td>Bagel 2.0 </td><td>1.270018  </td><td>0.49      </td><td>0.6530612 </td><td>0.71      </td><td>-0.3424903</td><td>-0.7133499</td><td>0         </td></tr>\n",
       "\t<tr><td>Blazer    </td><td>1.236685  </td><td>0.48      </td><td>0.6805556 </td><td>0.74      </td><td>-0.3011051</td><td>-0.7339692</td><td>0         </td></tr>\n",
       "\t<tr><td>Boston    </td><td>1.771016  </td><td>0.69      </td><td>0.8046875 </td><td>0.88      </td><td>-0.1278334</td><td>-0.3710637</td><td>1         </td></tr>\n",
       "\t<tr><td>Crypto    </td><td>1.078992  </td><td>0.42      </td><td>0.6530612 </td><td>0.71      </td><td>-0.3424903</td><td>-0.8675006</td><td>0         </td></tr>\n",
       "\t<tr><td>Cupid     </td><td>1.411304  </td><td>0.55      </td><td>0.7083333 </td><td>0.77      </td><td>-0.2613648</td><td>-0.5978370</td><td>0         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllll}\n",
       " Projects & Shannon diversity index & Normalized Shannon/NH & Simpson's index & Normalized Simpson/NGV & Distance to target Simpson & Distance to target Shannon & Success\\\\\n",
       "\\hline\n",
       "\t Bagel      & 1.459482   & 0.57       & 0.7377778  & 0.81       & -0.2107210 & -0.5621189 & 0         \\\\\n",
       "\t Bagel 2.0  & 1.270018   & 0.49       & 0.6530612  & 0.71       & -0.3424903 & -0.7133499 & 0         \\\\\n",
       "\t Blazer     & 1.236685   & 0.48       & 0.6805556  & 0.74       & -0.3011051 & -0.7339692 & 0         \\\\\n",
       "\t Boston     & 1.771016   & 0.69       & 0.8046875  & 0.88       & -0.1278334 & -0.3710637 & 1         \\\\\n",
       "\t Crypto     & 1.078992   & 0.42       & 0.6530612  & 0.71       & -0.3424903 & -0.8675006 & 0         \\\\\n",
       "\t Cupid      & 1.411304   & 0.55       & 0.7083333  & 0.77       & -0.2613648 & -0.5978370 & 0         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Projects | Shannon diversity index | Normalized Shannon/NH | Simpson's index | Normalized Simpson/NGV | Distance to target Simpson | Distance to target Shannon | Success |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Bagel      | 1.459482   | 0.57       | 0.7377778  | 0.81       | -0.2107210 | -0.5621189 | 0          |\n",
       "| Bagel 2.0  | 1.270018   | 0.49       | 0.6530612  | 0.71       | -0.3424903 | -0.7133499 | 0          |\n",
       "| Blazer     | 1.236685   | 0.48       | 0.6805556  | 0.74       | -0.3011051 | -0.7339692 | 0          |\n",
       "| Boston     | 1.771016   | 0.69       | 0.8046875  | 0.88       | -0.1278334 | -0.3710637 | 1          |\n",
       "| Crypto     | 1.078992   | 0.42       | 0.6530612  | 0.71       | -0.3424903 | -0.8675006 | 0          |\n",
       "| Cupid      | 1.411304   | 0.55       | 0.7083333  | 0.77       | -0.2613648 | -0.5978370 | 0          |\n",
       "\n"
      ],
      "text/plain": [
       "  Projects  Shannon diversity index Normalized Shannon/NH Simpson's index\n",
       "1 Bagel     1.459482                0.57                  0.7377778      \n",
       "2 Bagel 2.0 1.270018                0.49                  0.6530612      \n",
       "3 Blazer    1.236685                0.48                  0.6805556      \n",
       "4 Boston    1.771016                0.69                  0.8046875      \n",
       "5 Crypto    1.078992                0.42                  0.6530612      \n",
       "6 Cupid     1.411304                0.55                  0.7083333      \n",
       "  Normalized Simpson/NGV Distance to target Simpson Distance to target Shannon\n",
       "1 0.81                   -0.2107210                 -0.5621189                \n",
       "2 0.71                   -0.3424903                 -0.7133499                \n",
       "3 0.74                   -0.3011051                 -0.7339692                \n",
       "4 0.88                   -0.1278334                 -0.3710637                \n",
       "5 0.71                   -0.3424903                 -0.8675006                \n",
       "6 0.77                   -0.2613648                 -0.5978370                \n",
       "  Success\n",
       "1 0      \n",
       "2 0      \n",
       "3 0      \n",
       "4 1      \n",
       "5 0      \n",
       "6 0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(\"data.table\") #loading the data\n",
    "file_path <- \"C:/Users/kamil/Downloads/diversity.csv\"\n",
    "data_diversity <- fread(file_path,\n",
    " stringsAsFactors = F,\n",
    " data.table = T)\n",
    "\n",
    "head(data_diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAr7tNTU1oaGh8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\n4p/V4/2Q5QAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#install.packages(\"ggpubr\") #box plots of NGV scores of successful and unsuccessful projects \n",
    "library(\"ggpubr\")\n",
    "ggboxplot(data_diversity, x = \"Success\", y = \"Normalized Simpson/NGV\", \n",
    "          color = \"Success\", palette = c(\"#00AFBB\", \"#E7B800\"),\n",
    "        ylab = \"Simpson\", xlab = \"Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(data_diversity)[5] <- \"NGV\" #changing the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Success</th><th scope=col>count</th><th scope=col>mean</th><th scope=col>sd</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0         </td><td>25        </td><td>0.7324    </td><td>0.09841578</td></tr>\n",
       "\t<tr><td>1         </td><td> 5        </td><td>0.8760    </td><td>0.03577709</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " Success & count & mean & sd\\\\\n",
       "\\hline\n",
       "\t 0          & 25         & 0.7324     & 0.09841578\\\\\n",
       "\t 1          &  5         & 0.8760     & 0.03577709\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Success | count | mean | sd |\n",
       "|---|---|---|---|\n",
       "| 0          | 25         | 0.7324     | 0.09841578 |\n",
       "| 1          |  5         | 0.8760     | 0.03577709 |\n",
       "\n"
      ],
      "text/plain": [
       "  Success count mean   sd        \n",
       "1 0       25    0.7324 0.09841578\n",
       "2 1        5    0.8760 0.03577709"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(dplyr) #means and standard deviations of successful and unsuccessful projects\n",
    "group_by(data_diversity, Success) %>%\n",
    "  summarise(\n",
    "    count = n(),\n",
    "    mean = mean(NGV, na.rm = TRUE),\n",
    "    sd = sd(NGV, na.rm = TRUE)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tF test to compare two variances\n",
       "\n",
       "data:  NGV by Success\n",
       "F = 7.5669, num df = 24, denom df = 4, p-value = 0.06188\n",
       "alternative hypothesis: true ratio of variances is not equal to 1\n",
       "95 percent confidence interval:\n",
       "  0.8890894 25.5713630\n",
       "sample estimates:\n",
       "ratio of variances \n",
       "          7.566927 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res.ftest <- var.test(NGV ~ Success, data = data_diversity) #F-test\n",
    "res.ftest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value of F-test is p = 0.06188. Itâ€™s greater than the significance level alpha = 0.05 so there is no significant difference between the variances of the two sets of data. The classic t-test witch assume equality of the two variances can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "success <- data_diversity$NGV[data_diversity$Success==1] #groups for hypothesis testing\n",
    "no.success <- data_diversity$NGV[data_diversity$Success==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\tTwo Sample t-test\n",
       "\n",
       "data:  success and no.success\n",
       "t = 3.1822, df = 28, p-value = 0.001781\n",
       "alternative hypothesis: true difference in means is greater than 0\n",
       "95 percent confidence interval:\n",
       " 0.06683458        Inf\n",
       "sample estimates:\n",
       "mean of x mean of y \n",
       "   0.8760    0.7324 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.test(success, no.success, #hypothesis testing ('successful' cognitve diversity scores are greater than 'unsuccessful')\n",
    "        var.equal = TRUE, alternative = \"greater\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>prop_infj</th><th scope=col>prop_infp</th><th scope=col>prop_intj</th><th scope=col>prop_isfj</th><th scope=col>prop_isfp</th><th scope=col>prop_esfp</th><th scope=col>prop_intp</th><th scope=col>prop_istp</th><th scope=col>prop_enfj</th><th scope=col>prop_enfp</th><th scope=col>prop_estj</th><th scope=col>prop_estp</th><th scope=col>prop_entj</th><th scope=col>prop_istj</th><th scope=col>prop_entp</th><th scope=col>prop_esfj</th><th scope=col>GV</th><th scope=col>GV_p</th><th scope=col>Success</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.1333   </td><td>0.4000   </td><td>0.2000   </td><td>0.200    </td><td>0.0667   </td><td>0.0000   </td><td>0.0000   </td><td>0.0000   </td><td>0.0000   </td><td>0.0000   </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0.7377778</td><td>73.77778 </td><td>0        </td></tr>\n",
       "\t<tr><td>0.0000   </td><td>0.2857   </td><td>0.0714   </td><td>0.000    </td><td>0.0000   </td><td>0.0714   </td><td>0.5000   </td><td>0.0714   </td><td>0.0000   </td><td>0.0000   </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0.6530612</td><td>65.30612 </td><td>0        </td></tr>\n",
       "\t<tr><td>0.1667   </td><td>0.3333   </td><td>0.0833   </td><td>0.000    </td><td>0.0000   </td><td>0.0000   </td><td>0.4167   </td><td>0.0000   </td><td>0.0000   </td><td>0.0000   </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0.6805556</td><td>68.05556 </td><td>0        </td></tr>\n",
       "\t<tr><td>0.1875   </td><td>0.0625   </td><td>0.3125   </td><td>0.125    </td><td>0.0000   </td><td>0.0000   </td><td>0.0000   </td><td>0.1875   </td><td>0.0625   </td><td>0.0625   </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0.8046875</td><td>80.46875 </td><td>1        </td></tr>\n",
       "\t<tr><td>0.0000   </td><td>0.2857   </td><td>0.2857   </td><td>0.000    </td><td>0.0000   </td><td>0.0000   </td><td>0.4286   </td><td>0.0000   </td><td>0.0000   </td><td>0.0000   </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0.6530612</td><td>65.30612 </td><td>0        </td></tr>\n",
       "\t<tr><td>0.1250   </td><td>0.4583   </td><td>0.1250   </td><td>0.000    </td><td>0.0000   </td><td>0.0000   </td><td>0.2083   </td><td>0.0833   </td><td>0.0000   </td><td>0.0000   </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0        </td><td>0.7083333</td><td>70.83333 </td><td>0        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllll}\n",
       " prop\\_infj & prop\\_infp & prop\\_intj & prop\\_isfj & prop\\_isfp & prop\\_esfp & prop\\_intp & prop\\_istp & prop\\_enfj & prop\\_enfp & prop\\_estj & prop\\_estp & prop\\_entj & prop\\_istj & prop\\_entp & prop\\_esfj & GV & GV\\_p & Success\\\\\n",
       "\\hline\n",
       "\t 0.1333    & 0.4000    & 0.2000    & 0.200     & 0.0667    & 0.0000    & 0.0000    & 0.0000    & 0.0000    & 0.0000    & 0         & 0         & 0         & 0         & 0         & 0         & 0.7377778 & 73.77778  & 0        \\\\\n",
       "\t 0.0000    & 0.2857    & 0.0714    & 0.000     & 0.0000    & 0.0714    & 0.5000    & 0.0714    & 0.0000    & 0.0000    & 0         & 0         & 0         & 0         & 0         & 0         & 0.6530612 & 65.30612  & 0        \\\\\n",
       "\t 0.1667    & 0.3333    & 0.0833    & 0.000     & 0.0000    & 0.0000    & 0.4167    & 0.0000    & 0.0000    & 0.0000    & 0         & 0         & 0         & 0         & 0         & 0         & 0.6805556 & 68.05556  & 0        \\\\\n",
       "\t 0.1875    & 0.0625    & 0.3125    & 0.125     & 0.0000    & 0.0000    & 0.0000    & 0.1875    & 0.0625    & 0.0625    & 0         & 0         & 0         & 0         & 0         & 0         & 0.8046875 & 80.46875  & 1        \\\\\n",
       "\t 0.0000    & 0.2857    & 0.2857    & 0.000     & 0.0000    & 0.0000    & 0.4286    & 0.0000    & 0.0000    & 0.0000    & 0         & 0         & 0         & 0         & 0         & 0         & 0.6530612 & 65.30612  & 0        \\\\\n",
       "\t 0.1250    & 0.4583    & 0.1250    & 0.000     & 0.0000    & 0.0000    & 0.2083    & 0.0833    & 0.0000    & 0.0000    & 0         & 0         & 0         & 0         & 0         & 0         & 0.7083333 & 70.83333  & 0        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| prop_infj | prop_infp | prop_intj | prop_isfj | prop_isfp | prop_esfp | prop_intp | prop_istp | prop_enfj | prop_enfp | prop_estj | prop_estp | prop_entj | prop_istj | prop_entp | prop_esfj | GV | GV_p | Success |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0.1333    | 0.4000    | 0.2000    | 0.200     | 0.0667    | 0.0000    | 0.0000    | 0.0000    | 0.0000    | 0.0000    | 0         | 0         | 0         | 0         | 0         | 0         | 0.7377778 | 73.77778  | 0         |\n",
       "| 0.0000    | 0.2857    | 0.0714    | 0.000     | 0.0000    | 0.0714    | 0.5000    | 0.0714    | 0.0000    | 0.0000    | 0         | 0         | 0         | 0         | 0         | 0         | 0.6530612 | 65.30612  | 0         |\n",
       "| 0.1667    | 0.3333    | 0.0833    | 0.000     | 0.0000    | 0.0000    | 0.4167    | 0.0000    | 0.0000    | 0.0000    | 0         | 0         | 0         | 0         | 0         | 0         | 0.6805556 | 68.05556  | 0         |\n",
       "| 0.1875    | 0.0625    | 0.3125    | 0.125     | 0.0000    | 0.0000    | 0.0000    | 0.1875    | 0.0625    | 0.0625    | 0         | 0         | 0         | 0         | 0         | 0         | 0.8046875 | 80.46875  | 1         |\n",
       "| 0.0000    | 0.2857    | 0.2857    | 0.000     | 0.0000    | 0.0000    | 0.4286    | 0.0000    | 0.0000    | 0.0000    | 0         | 0         | 0         | 0         | 0         | 0         | 0.6530612 | 65.30612  | 0         |\n",
       "| 0.1250    | 0.4583    | 0.1250    | 0.000     | 0.0000    | 0.0000    | 0.2083    | 0.0833    | 0.0000    | 0.0000    | 0         | 0         | 0         | 0         | 0         | 0         | 0.7083333 | 70.83333  | 0         |\n",
       "\n"
      ],
      "text/plain": [
       "  prop_infj prop_infp prop_intj prop_isfj prop_isfp prop_esfp prop_intp\n",
       "1 0.1333    0.4000    0.2000    0.200     0.0667    0.0000    0.0000   \n",
       "2 0.0000    0.2857    0.0714    0.000     0.0000    0.0714    0.5000   \n",
       "3 0.1667    0.3333    0.0833    0.000     0.0000    0.0000    0.4167   \n",
       "4 0.1875    0.0625    0.3125    0.125     0.0000    0.0000    0.0000   \n",
       "5 0.0000    0.2857    0.2857    0.000     0.0000    0.0000    0.4286   \n",
       "6 0.1250    0.4583    0.1250    0.000     0.0000    0.0000    0.2083   \n",
       "  prop_istp prop_enfj prop_enfp prop_estj prop_estp prop_entj prop_istj\n",
       "1 0.0000    0.0000    0.0000    0         0         0         0        \n",
       "2 0.0714    0.0000    0.0000    0         0         0         0        \n",
       "3 0.0000    0.0000    0.0000    0         0         0         0        \n",
       "4 0.1875    0.0625    0.0625    0         0         0         0        \n",
       "5 0.0000    0.0000    0.0000    0         0         0         0        \n",
       "6 0.0833    0.0000    0.0000    0         0         0         0        \n",
       "  prop_entp prop_esfj GV        GV_p     Success\n",
       "1 0         0         0.7377778 73.77778 0      \n",
       "2 0         0         0.6530612 65.30612 0      \n",
       "3 0         0         0.6805556 68.05556 0      \n",
       "4 0         0         0.8046875 80.46875 1      \n",
       "5 0         0         0.6530612 65.30612 0      \n",
       "6 0         0         0.7083333 70.83333 0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(\"data.table\") #loading data for regression with GV\n",
    "file_path <- \"C:/Users/kamil/Desktop/for_regression.csv\"\n",
    "regr <- fread(file_path,\n",
    " stringsAsFactors = F,\n",
    " data.table = T)\n",
    "\n",
    "head(regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"1  linear dependencies found\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Subset selection object\n",
       "Call: regsubsets.formula(Success ~ GV + prop_infj + prop_infp + prop_intj + \n",
       "    prop_isfj + prop_isfp + prop_esfp + prop_intp + prop_istp + \n",
       "    prop_enfj + prop_enfp + prop_estj + prop_estp + prop_entj + \n",
       "    prop_istj + prop_entp + prop_esfj, data = regr, nvmax = 18)\n",
       "17 Variables  (and intercept)\n",
       "          Forced in Forced out\n",
       "GV            FALSE      FALSE\n",
       "prop_infj     FALSE      FALSE\n",
       "prop_infp     FALSE      FALSE\n",
       "prop_intj     FALSE      FALSE\n",
       "prop_isfj     FALSE      FALSE\n",
       "prop_isfp     FALSE      FALSE\n",
       "prop_esfp     FALSE      FALSE\n",
       "prop_intp     FALSE      FALSE\n",
       "prop_istp     FALSE      FALSE\n",
       "prop_enfj     FALSE      FALSE\n",
       "prop_enfp     FALSE      FALSE\n",
       "prop_estj     FALSE      FALSE\n",
       "prop_entj     FALSE      FALSE\n",
       "prop_istj     FALSE      FALSE\n",
       "prop_entp     FALSE      FALSE\n",
       "prop_esfj     FALSE      FALSE\n",
       "prop_estp     FALSE      FALSE\n",
       "1 subsets of each size up to 16\n",
       "Selection Algorithm: exhaustive\n",
       "          GV  prop_infj prop_infp prop_intj prop_isfj prop_isfp prop_esfp\n",
       "1  ( 1 )  \"*\" \" \"       \" \"       \" \"       \" \"       \" \"       \" \"      \n",
       "2  ( 1 )  \"*\" \" \"       \" \"       \" \"       \" \"       \" \"       \" \"      \n",
       "3  ( 1 )  \"*\" \" \"       \" \"       \" \"       \" \"       \" \"       \" \"      \n",
       "4  ( 1 )  \"*\" \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"      \n",
       "5  ( 1 )  \"*\" \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"      \n",
       "6  ( 1 )  \"*\" \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"      \n",
       "7  ( 1 )  \"*\" \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"      \n",
       "8  ( 1 )  \"*\" \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"      \n",
       "9  ( 1 )  \"*\" \" \"       \" \"       \"*\"       \"*\"       \" \"       \"*\"      \n",
       "10  ( 1 ) \"*\" \" \"       \" \"       \"*\"       \"*\"       \" \"       \"*\"      \n",
       "11  ( 1 ) \"*\" \" \"       \" \"       \"*\"       \"*\"       \" \"       \"*\"      \n",
       "12  ( 1 ) \"*\" \"*\"       \"*\"       \"*\"       \" \"       \"*\"       \" \"      \n",
       "13  ( 1 ) \"*\" \"*\"       \"*\"       \"*\"       \" \"       \"*\"       \" \"      \n",
       "14  ( 1 ) \"*\" \"*\"       \"*\"       \"*\"       \" \"       \"*\"       \" \"      \n",
       "15  ( 1 ) \"*\" \"*\"       \"*\"       \"*\"       \"*\"       \"*\"       \"*\"      \n",
       "16  ( 1 ) \"*\" \"*\"       \"*\"       \"*\"       \"*\"       \"*\"       \"*\"      \n",
       "          prop_intp prop_istp prop_enfj prop_enfp prop_estj prop_estp prop_entj\n",
       "1  ( 1 )  \" \"       \" \"       \" \"       \" \"       \" \"       \" \"       \" \"      \n",
       "2  ( 1 )  \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "3  ( 1 )  \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "4  ( 1 )  \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "5  ( 1 )  \" \"       \"*\"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "6  ( 1 )  \" \"       \"*\"       \"*\"       \" \"       \" \"       \" \"       \"*\"      \n",
       "7  ( 1 )  \" \"       \"*\"       \"*\"       \" \"       \" \"       \" \"       \"*\"      \n",
       "8  ( 1 )  \" \"       \"*\"       \"*\"       \" \"       \"*\"       \" \"       \"*\"      \n",
       "9  ( 1 )  \" \"       \" \"       \"*\"       \" \"       \"*\"       \" \"       \"*\"      \n",
       "10  ( 1 ) \" \"       \"*\"       \"*\"       \" \"       \"*\"       \" \"       \"*\"      \n",
       "11  ( 1 ) \"*\"       \"*\"       \"*\"       \" \"       \"*\"       \" \"       \"*\"      \n",
       "12  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \"*\"      \n",
       "13  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \"*\"      \n",
       "14  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \"*\"       \"*\"      \n",
       "15  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \" \"       \"*\"      \n",
       "16  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \"*\"      \n",
       "          prop_istj prop_entp prop_esfj\n",
       "1  ( 1 )  \" \"       \" \"       \" \"      \n",
       "2  ( 1 )  \" \"       \" \"       \" \"      \n",
       "3  ( 1 )  \"*\"       \" \"       \" \"      \n",
       "4  ( 1 )  \"*\"       \" \"       \" \"      \n",
       "5  ( 1 )  \"*\"       \" \"       \" \"      \n",
       "6  ( 1 )  \"*\"       \" \"       \" \"      \n",
       "7  ( 1 )  \"*\"       \"*\"       \" \"      \n",
       "8  ( 1 )  \"*\"       \"*\"       \" \"      \n",
       "9  ( 1 )  \"*\"       \"*\"       \" \"      \n",
       "10  ( 1 ) \"*\"       \"*\"       \" \"      \n",
       "11  ( 1 ) \"*\"       \"*\"       \" \"      \n",
       "12  ( 1 ) \"*\"       \" \"       \" \"      \n",
       "13  ( 1 ) \"*\"       \"*\"       \" \"      \n",
       "14  ( 1 ) \"*\"       \"*\"       \"*\"      \n",
       "15  ( 1 ) \"*\"       \"*\"       \"*\"      \n",
       "16  ( 1 ) \"*\"       \"*\"       \"*\"      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#install.packages(\"leaps\")\n",
    "library(leaps)\n",
    "models <- regsubsets(Success ~ GV + \n",
    "                              prop_infj+ prop_infp+prop_intj+prop_isfj+prop_isfp+prop_esfp+prop_intp+prop_istp+prop_enfj+prop_enfp+prop_estj+prop_estp+prop_entj+prop_istj+prop_entp+prop_esfj, \n",
    "                            data = regr, nvmax = 18)\n",
    "\n",
    "summary(models) #best subsets with GV scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Adj.R2</th><th scope=col>CP</th><th scope=col>BIC</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>4</td><td>4</td><td>4</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " Adj.R2 & CP & BIC\\\\\n",
       "\\hline\n",
       "\t 4 & 4 & 4\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Adj.R2 | CP | BIC |\n",
       "|---|---|---|\n",
       "| 4 | 4 | 4 |\n",
       "\n"
      ],
      "text/plain": [
       "  Adj.R2 CP BIC\n",
       "1 4      4  4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_sum <- summary(models) #best subset according to AdjR, CP and BIC\n",
    "data.frame(\n",
    "  Adj.R2 = which.max(res_sum$adjr2),\n",
    "  CP = which.min(res_sum$cp),\n",
    "  BIC = which.min(res_sum$bic)\n",
    ") #the one with 4 independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Success ~ GV + prop_intj + prop_enfj + prop_istj\n",
       "<environment: 0x0000000041a6b8f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_model_formula(4, models, \"Success\") #formula of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>prop_infj</th><th scope=col>prop_infp</th><th scope=col>prop_intj</th><th scope=col>prop_isfj</th><th scope=col>prop_isfp</th><th scope=col>prop_esfp</th><th scope=col>prop_intp</th><th scope=col>prop_istp</th><th scope=col>prop_enfj</th><th scope=col>prop_enfp</th><th scope=col>prop_estj</th><th scope=col>prop_estp</th><th scope=col>prop_entj</th><th scope=col>prop_istj</th><th scope=col>prop_entp</th><th scope=col>prop_esfj</th><th scope=col>Entropy</th><th scope=col>Success</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.1333  </td><td>0.4000  </td><td>0.2000  </td><td>0.200   </td><td>0.0667  </td><td>0.0000  </td><td>0.0000  </td><td>0.0000  </td><td>0.0000  </td><td>0.0000  </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1.459482</td><td>0       </td></tr>\n",
       "\t<tr><td>0.0000  </td><td>0.2857  </td><td>0.0714  </td><td>0.000   </td><td>0.0000  </td><td>0.0714  </td><td>0.5000  </td><td>0.0714  </td><td>0.0000  </td><td>0.0000  </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1.270018</td><td>0       </td></tr>\n",
       "\t<tr><td>0.1667  </td><td>0.3333  </td><td>0.0833  </td><td>0.000   </td><td>0.0000  </td><td>0.0000  </td><td>0.4167  </td><td>0.0000  </td><td>0.0000  </td><td>0.0000  </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1.236685</td><td>0       </td></tr>\n",
       "\t<tr><td>0.1875  </td><td>0.0625  </td><td>0.3125  </td><td>0.125   </td><td>0.0000  </td><td>0.0000  </td><td>0.0000  </td><td>0.1875  </td><td>0.0625  </td><td>0.0625  </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1.771016</td><td>1       </td></tr>\n",
       "\t<tr><td>0.0000  </td><td>0.2857  </td><td>0.2857  </td><td>0.000   </td><td>0.0000  </td><td>0.0000  </td><td>0.4286  </td><td>0.0000  </td><td>0.0000  </td><td>0.0000  </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1.078992</td><td>0       </td></tr>\n",
       "\t<tr><td>0.1250  </td><td>0.4583  </td><td>0.1250  </td><td>0.000   </td><td>0.0000  </td><td>0.0000  </td><td>0.2083  </td><td>0.0833  </td><td>0.0000  </td><td>0.0000  </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>0       </td><td>1.411304</td><td>0       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllll}\n",
       " prop\\_infj & prop\\_infp & prop\\_intj & prop\\_isfj & prop\\_isfp & prop\\_esfp & prop\\_intp & prop\\_istp & prop\\_enfj & prop\\_enfp & prop\\_estj & prop\\_estp & prop\\_entj & prop\\_istj & prop\\_entp & prop\\_esfj & Entropy & Success\\\\\n",
       "\\hline\n",
       "\t 0.1333   & 0.4000   & 0.2000   & 0.200    & 0.0667   & 0.0000   & 0.0000   & 0.0000   & 0.0000   & 0.0000   & 0        & 0        & 0        & 0        & 0        & 0        & 1.459482 & 0       \\\\\n",
       "\t 0.0000   & 0.2857   & 0.0714   & 0.000    & 0.0000   & 0.0714   & 0.5000   & 0.0714   & 0.0000   & 0.0000   & 0        & 0        & 0        & 0        & 0        & 0        & 1.270018 & 0       \\\\\n",
       "\t 0.1667   & 0.3333   & 0.0833   & 0.000    & 0.0000   & 0.0000   & 0.4167   & 0.0000   & 0.0000   & 0.0000   & 0        & 0        & 0        & 0        & 0        & 0        & 1.236685 & 0       \\\\\n",
       "\t 0.1875   & 0.0625   & 0.3125   & 0.125    & 0.0000   & 0.0000   & 0.0000   & 0.1875   & 0.0625   & 0.0625   & 0        & 0        & 0        & 0        & 0        & 0        & 1.771016 & 1       \\\\\n",
       "\t 0.0000   & 0.2857   & 0.2857   & 0.000    & 0.0000   & 0.0000   & 0.4286   & 0.0000   & 0.0000   & 0.0000   & 0        & 0        & 0        & 0        & 0        & 0        & 1.078992 & 0       \\\\\n",
       "\t 0.1250   & 0.4583   & 0.1250   & 0.000    & 0.0000   & 0.0000   & 0.2083   & 0.0833   & 0.0000   & 0.0000   & 0        & 0        & 0        & 0        & 0        & 0        & 1.411304 & 0       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| prop_infj | prop_infp | prop_intj | prop_isfj | prop_isfp | prop_esfp | prop_intp | prop_istp | prop_enfj | prop_enfp | prop_estj | prop_estp | prop_entj | prop_istj | prop_entp | prop_esfj | Entropy | Success |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0.1333   | 0.4000   | 0.2000   | 0.200    | 0.0667   | 0.0000   | 0.0000   | 0.0000   | 0.0000   | 0.0000   | 0        | 0        | 0        | 0        | 0        | 0        | 1.459482 | 0        |\n",
       "| 0.0000   | 0.2857   | 0.0714   | 0.000    | 0.0000   | 0.0714   | 0.5000   | 0.0714   | 0.0000   | 0.0000   | 0        | 0        | 0        | 0        | 0        | 0        | 1.270018 | 0        |\n",
       "| 0.1667   | 0.3333   | 0.0833   | 0.000    | 0.0000   | 0.0000   | 0.4167   | 0.0000   | 0.0000   | 0.0000   | 0        | 0        | 0        | 0        | 0        | 0        | 1.236685 | 0        |\n",
       "| 0.1875   | 0.0625   | 0.3125   | 0.125    | 0.0000   | 0.0000   | 0.0000   | 0.1875   | 0.0625   | 0.0625   | 0        | 0        | 0        | 0        | 0        | 0        | 1.771016 | 1        |\n",
       "| 0.0000   | 0.2857   | 0.2857   | 0.000    | 0.0000   | 0.0000   | 0.4286   | 0.0000   | 0.0000   | 0.0000   | 0        | 0        | 0        | 0        | 0        | 0        | 1.078992 | 0        |\n",
       "| 0.1250   | 0.4583   | 0.1250   | 0.000    | 0.0000   | 0.0000   | 0.2083   | 0.0833   | 0.0000   | 0.0000   | 0        | 0        | 0        | 0        | 0        | 0        | 1.411304 | 0        |\n",
       "\n"
      ],
      "text/plain": [
       "  prop_infj prop_infp prop_intj prop_isfj prop_isfp prop_esfp prop_intp\n",
       "1 0.1333    0.4000    0.2000    0.200     0.0667    0.0000    0.0000   \n",
       "2 0.0000    0.2857    0.0714    0.000     0.0000    0.0714    0.5000   \n",
       "3 0.1667    0.3333    0.0833    0.000     0.0000    0.0000    0.4167   \n",
       "4 0.1875    0.0625    0.3125    0.125     0.0000    0.0000    0.0000   \n",
       "5 0.0000    0.2857    0.2857    0.000     0.0000    0.0000    0.4286   \n",
       "6 0.1250    0.4583    0.1250    0.000     0.0000    0.0000    0.2083   \n",
       "  prop_istp prop_enfj prop_enfp prop_estj prop_estp prop_entj prop_istj\n",
       "1 0.0000    0.0000    0.0000    0         0         0         0        \n",
       "2 0.0714    0.0000    0.0000    0         0         0         0        \n",
       "3 0.0000    0.0000    0.0000    0         0         0         0        \n",
       "4 0.1875    0.0625    0.0625    0         0         0         0        \n",
       "5 0.0000    0.0000    0.0000    0         0         0         0        \n",
       "6 0.0833    0.0000    0.0000    0         0         0         0        \n",
       "  prop_entp prop_esfj Entropy  Success\n",
       "1 0         0         1.459482 0      \n",
       "2 0         0         1.270018 0      \n",
       "3 0         0         1.236685 0      \n",
       "4 0         0         1.771016 1      \n",
       "5 0         0         1.078992 0      \n",
       "6 0         0         1.411304 0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(\"data.table\") #loading data for regression with Entropy\n",
    "file_path <- \"C:/Users/kamil/Desktop/for_regression2.csv\"\n",
    "regr2 <- fread(file_path,\n",
    " stringsAsFactors = F,\n",
    " data.table = T)\n",
    "\n",
    "head(regr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in leaps.setup(x, y, wt = wt, nbest = nbest, nvmax = nvmax, force.in = force.in, :\n",
      "\"1  linear dependencies found\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordering variables and trying again:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Subset selection object\n",
       "Call: regsubsets.formula(Success ~ Entropy + prop_infj + prop_infp + \n",
       "    prop_intj + prop_isfj + prop_isfp + prop_esfp + prop_intp + \n",
       "    prop_istp + prop_enfj + prop_enfp + prop_estj + prop_estp + \n",
       "    prop_entj + prop_istj + prop_entp + prop_esfj, data = regr2, \n",
       "    nvmax = 18)\n",
       "17 Variables  (and intercept)\n",
       "          Forced in Forced out\n",
       "Entropy       FALSE      FALSE\n",
       "prop_infj     FALSE      FALSE\n",
       "prop_infp     FALSE      FALSE\n",
       "prop_intj     FALSE      FALSE\n",
       "prop_isfj     FALSE      FALSE\n",
       "prop_isfp     FALSE      FALSE\n",
       "prop_esfp     FALSE      FALSE\n",
       "prop_intp     FALSE      FALSE\n",
       "prop_istp     FALSE      FALSE\n",
       "prop_enfj     FALSE      FALSE\n",
       "prop_enfp     FALSE      FALSE\n",
       "prop_estj     FALSE      FALSE\n",
       "prop_entj     FALSE      FALSE\n",
       "prop_istj     FALSE      FALSE\n",
       "prop_entp     FALSE      FALSE\n",
       "prop_esfj     FALSE      FALSE\n",
       "prop_estp     FALSE      FALSE\n",
       "1 subsets of each size up to 16\n",
       "Selection Algorithm: exhaustive\n",
       "          Entropy prop_infj prop_infp prop_intj prop_isfj prop_isfp prop_esfp\n",
       "1  ( 1 )  \"*\"     \" \"       \" \"       \" \"       \" \"       \" \"       \" \"      \n",
       "2  ( 1 )  \"*\"     \" \"       \" \"       \" \"       \" \"       \" \"       \" \"      \n",
       "3  ( 1 )  \"*\"     \" \"       \" \"       \" \"       \" \"       \" \"       \" \"      \n",
       "4  ( 1 )  \"*\"     \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"      \n",
       "5  ( 1 )  \"*\"     \" \"       \" \"       \"*\"       \" \"       \"*\"       \" \"      \n",
       "6  ( 1 )  \"*\"     \" \"       \" \"       \"*\"       \" \"       \"*\"       \" \"      \n",
       "7  ( 1 )  \"*\"     \" \"       \" \"       \"*\"       \" \"       \"*\"       \" \"      \n",
       "8  ( 1 )  \"*\"     \"*\"       \"*\"       \"*\"       \" \"       \" \"       \" \"      \n",
       "9  ( 1 )  \"*\"     \" \"       \" \"       \"*\"       \"*\"       \" \"       \"*\"      \n",
       "10  ( 1 ) \"*\"     \"*\"       \"*\"       \"*\"       \" \"       \" \"       \" \"      \n",
       "11  ( 1 ) \"*\"     \"*\"       \"*\"       \"*\"       \" \"       \" \"       \"*\"      \n",
       "12  ( 1 ) \"*\"     \"*\"       \"*\"       \"*\"       \" \"       \" \"       \"*\"      \n",
       "13  ( 1 ) \"*\"     \"*\"       \"*\"       \"*\"       \" \"       \" \"       \"*\"      \n",
       "14  ( 1 ) \"*\"     \"*\"       \"*\"       \"*\"       \" \"       \"*\"       \"*\"      \n",
       "15  ( 1 ) \"*\"     \"*\"       \"*\"       \"*\"       \"*\"       \"*\"       \" \"      \n",
       "16  ( 1 ) \"*\"     \"*\"       \"*\"       \"*\"       \"*\"       \"*\"       \"*\"      \n",
       "          prop_intp prop_istp prop_enfj prop_enfp prop_estj prop_estp prop_entj\n",
       "1  ( 1 )  \" \"       \" \"       \" \"       \" \"       \" \"       \" \"       \" \"      \n",
       "2  ( 1 )  \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "3  ( 1 )  \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "4  ( 1 )  \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "5  ( 1 )  \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "6  ( 1 )  \" \"       \" \"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "7  ( 1 )  \" \"       \"*\"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "8  ( 1 )  \"*\"       \"*\"       \"*\"       \" \"       \" \"       \" \"       \" \"      \n",
       "9  ( 1 )  \" \"       \"*\"       \"*\"       \" \"       \" \"       \"*\"       \" \"      \n",
       "10  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \" \"       \"*\"      \n",
       "11  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \" \"       \"*\"      \n",
       "12  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \"*\"       \"*\"      \n",
       "13  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \"*\"       \"*\"      \n",
       "14  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \"*\"       \"*\"      \n",
       "15  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \"*\"      \n",
       "16  ( 1 ) \"*\"       \"*\"       \"*\"       \"*\"       \"*\"       \" \"       \"*\"      \n",
       "          prop_istj prop_entp prop_esfj\n",
       "1  ( 1 )  \" \"       \" \"       \" \"      \n",
       "2  ( 1 )  \" \"       \" \"       \" \"      \n",
       "3  ( 1 )  \"*\"       \" \"       \" \"      \n",
       "4  ( 1 )  \"*\"       \" \"       \" \"      \n",
       "5  ( 1 )  \"*\"       \" \"       \" \"      \n",
       "6  ( 1 )  \"*\"       \"*\"       \" \"      \n",
       "7  ( 1 )  \"*\"       \"*\"       \" \"      \n",
       "8  ( 1 )  \"*\"       \" \"       \" \"      \n",
       "9  ( 1 )  \"*\"       \"*\"       \" \"      \n",
       "10  ( 1 ) \"*\"       \" \"       \" \"      \n",
       "11  ( 1 ) \"*\"       \" \"       \" \"      \n",
       "12  ( 1 ) \"*\"       \" \"       \" \"      \n",
       "13  ( 1 ) \"*\"       \"*\"       \" \"      \n",
       "14  ( 1 ) \"*\"       \"*\"       \" \"      \n",
       "15  ( 1 ) \"*\"       \"*\"       \"*\"      \n",
       "16  ( 1 ) \"*\"       \"*\"       \"*\"      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(leaps)\n",
    "models2 <- regsubsets(Success ~ Entropy + \n",
    "                              prop_infj+ prop_infp+prop_intj+prop_isfj+prop_isfp+prop_esfp+prop_intp+prop_istp+prop_enfj+prop_enfp+prop_estj+prop_estp+prop_entj+prop_istj+prop_entp+prop_esfj, \n",
    "                            data = regr2, nvmax = 18)\n",
    "\n",
    "summary(models2)  #best subsets wtih Entropy scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Adj.R2</th><th scope=col>CP</th><th scope=col>BIC</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>6</td><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " Adj.R2 & CP & BIC\\\\\n",
       "\\hline\n",
       "\t 6 & 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Adj.R2 | CP | BIC |\n",
       "|---|---|---|\n",
       "| 6 | 1 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "  Adj.R2 CP BIC\n",
       "1 6      1  1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_sum2 <- summary(models2) #best subset according to AdjR, CP and BIC\n",
    "data.frame(\n",
    "  Adj.R2 = which.max(res_sum2$adjr2),\n",
    "  CP = which.min(res_sum2$cp),\n",
    "  BIC = which.min(res_sum2$bic)\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Success ~ Entropy\n",
       "<environment: 0x000000006be686d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_model_formula(1, models2, \"Success\") #formula of the best model accorrding to CP and BIC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Success ~ Entropy, family = binomial, data = regr2)\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-1.54268  -0.36674  -0.19347  -0.09975   1.72964  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept)  -12.234      4.890  -2.502   0.0124 *\n",
       "Entropy        6.732      2.858   2.356   0.0185 *\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 27.034  on 29  degrees of freedom\n",
       "Residual deviance: 16.669  on 28  degrees of freedom\n",
       "AIC: 20.669\n",
       "\n",
       "Number of Fisher Scoring iterations: 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_3 <- glm(Success ~ Entropy, data = regr2, family=binomial) #Entropy as the only predictor\n",
    "summary(logit_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Success ~ GV_p, family = binomial, data = regr)\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-1.35378  -0.37560  -0.10361  -0.03177   1.89307  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)  \n",
       "(Intercept) -25.2354    11.8027  -2.138   0.0325 *\n",
       "GV_p          0.3127     0.1496   2.090   0.0366 *\n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 27.034  on 29  degrees of freedom\n",
       "Residual deviance: 15.920  on 28  degrees of freedom\n",
       "AIC: 19.92\n",
       "\n",
       "Number of Fisher Scoring iterations: 7\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logit_4 <- glm(Success ~ GV_p, data = regr, family=binomial) #GV as the only predictor\n",
    "summary(logit_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
